{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cff6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from keras import optimizers\n",
    "#from tensorflow.keras.layers import MaxPooling2D, BatchNormalization, Activation,Flatten, Dense\n",
    "from keras.layers import Conv2D, Dropout, Flatten, Dense, LeakyReLU, Reshape, BatchNormalization, ReLU, MaxPooling2D, ZeroPadding2D\n",
    "#from keras.utils.np_utils import to_categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f7ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 56, 56, 64)        256       \n",
      "=================================================================\n",
      "Total params: 1,088\n",
      "Trainable params: 960\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### prepating 1:\n",
    "def preprocess(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (2,2), input_shape = img_size, strides = 2))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())    ## instead of local response normalisation, I added Batchnormalisation.\n",
    "    return model\n",
    "    \n",
    "model1 = preprocess((224,224,3))\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43afc040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 96)        6240      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 208)       179920    \n",
      "=================================================================\n",
      "Total params: 186,160\n",
      "Trainable params: 186,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#  preparing the 2.a of the model..\n",
    "\n",
    "# InputA = (56, 56, 64)\n",
    "# InputB = (56, 56, 64)\n",
    "\n",
    "# x = Conv2D(96, (1,1), strides = 1, activation = \"relu\")(InputA)\n",
    "# x = Conv2D(208, (3,3),  strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "# x = Model(inputs = InputA, outputs = x)\n",
    "\n",
    "\n",
    "# y = MaxPooling2D(pool_size = (1,1))(InputsB)\n",
    "# y = Conv2D(64, (1,1), strides = 1, activation = \"relu\")(y)\n",
    "# y = Model(inputs = InputB, outputs = y)\n",
    "\n",
    "# combined = Concatenate([x.output, y.output])\n",
    "\n",
    "# final2 = MaxPooling2D(pool_size = (2,2))(combined)\n",
    "\n",
    "def preprocess(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    model.add(Conv2D(208, (3,3), input_shape = img_size, strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    return model\n",
    "    \n",
    "model2 = preprocess((56,56,64))\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea0a2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 64)        4160      \n",
      "=================================================================\n",
      "Total params: 4,160\n",
      "Trainable params: 4,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#  preparing the 2.b of the model..\n",
    "\n",
    "def preprocess(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))\n",
    "    model.add(Conv2D(64, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    return model\n",
    "    \n",
    "model3 = preprocess((56,56,64))\n",
    "print(model3.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ba5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 = Concatenate([model2.outputs, model3.outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48adeea8",
   "metadata": {},
   "source": [
    "#   NOW, FIRST ABOVE, WE CONCACENATED 2.a and 2.b and then we shall add an pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6449354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 96)        26208     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 208)       20176     \n",
      "=================================================================\n",
      "Total params: 46,384\n",
      "Trainable params: 46,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# preparing 3.a\n",
    "\n",
    "def preprocess(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    model.add(Conv2D(208, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    return model\n",
    "    \n",
    "model4 = preprocess((28,28,272))   # look at dimension we will get this after we concaenate 2.a and 2.b.\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6d795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 272)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 64)        17472     \n",
      "=================================================================\n",
      "Total params: 17,472\n",
      "Trainable params: 17,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# preparing 3.b\n",
    "\n",
    "def preprocess(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))\n",
    "    model.add(Conv2D(64, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    return model\n",
    "    \n",
    "model5 = preprocess((28,28,272))\n",
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "165fff19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Concatenate' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a86fcc4087b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfinal2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m272\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfinal2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Concatenate' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "final2 = Concatenate([model4.outputs, model5.outputs])\n",
    "img_size = (272, 28, 28)\n",
    "final2.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3a4a0",
   "metadata": {},
   "source": [
    "# now, above concacenated and then adding pooling layer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Now, finally we have to add the classifier.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbb1737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_144 (ZeroPadd (None, 654, 504, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 324, 249, 64)      9472      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_145 (ZeroPadd (None, 324, 249, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 161, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 161, 124, 64)      256       \n",
      "=================================================================\n",
      "Total params: 9,728\n",
      "Trainable params: 9,600\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001889482F340>\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001889582BF40>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer should be called on a list of at least 2 inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e03f73f1eeb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m###  Now, finally we have to add the classifier..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-e03f73f1eeb5>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmodel_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel2_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel2_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel2_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    219\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2641\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2644\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     \u001b[1;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;31m# Used purely for shape validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m       raise ValueError('A `Concatenate` layer should be called '\n\u001b[0m\u001b[0;32m    494\u001b[0m                        'on a list of at least 2 inputs')\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer should be called on a list of at least 2 inputs"
     ]
    }
   ],
   "source": [
    "def preprocess():#train_X, valid_X, train_Y, valid_Y):\n",
    "    \n",
    "    img_size = (640,490,3)\n",
    "    ### prepating 1\n",
    "    model1 = Sequential()\n",
    "    model1.add(ZeroPadding2D(padding=(7, 7), data_format=None, input_shape = img_size))\n",
    "    model1.add(Conv2D(64, (7,7), input_shape = img_size, strides = 2, activation = \"relu\"))\n",
    "    model1.add(ZeroPadding2D(padding=(0, 0), data_format=None))\n",
    "    model1.add(MaxPooling2D(pool_size=(3, 3), strides = 2))\n",
    "    model1.add(BatchNormalization())  \n",
    "    \n",
    "    model1.summary()\n",
    "    #  preparing the 2.a of the model..\n",
    "\n",
    "    model2_a = Sequential()\n",
    "    model2_a.add(ZeroPadding2D(padding=(0, 0), data_format=None, input_shape = img_size))\n",
    "    model2_a.add(Conv2D(96, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    #model1.add(ZeroPadding2D(padding=(1, 1), data_format=None)\n",
    "    model2_a.add(Conv2D(208, (3,3), input_shape = img_size, strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "   \n",
    "    #  preparing the 2.b of the model..\n",
    "\n",
    "    model2_b = Sequential()\n",
    "    model2_b.add(ZeroPadding2D(padding=(1, 1), data_format=None, input_shape = img_size))\n",
    "    model2_b.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))\n",
    "    model2_b.add(ZeroPadding2D(padding=(0, 0), data_format=None))\n",
    "    model2_b.add(Conv2D(64, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    print(model2_a)\n",
    "    print(model2_b)\n",
    "    model_2 = Sequential(model2_a, model2_b)\n",
    "    \n",
    "    model_2.add(Concatenate([model2_a, model2_b]))\n",
    "    model_2.add(ZeroPadding2D(padding=(0, 0), data_format=None, input_shape = img_size))\n",
    "    model_2.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))\n",
    "    # preparing 3.a\n",
    "\n",
    "    model3_a = Sequential()\n",
    "    model3_a.add(ZeroPadding2D(padding=(0, 0), data_format=None, input_shape = img_size))\n",
    "    model3_a.add(Conv2D(96, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    model3_a.add(ZeroPadding2D(padding=(1, 1), data_format=None))\n",
    "    model3_a.add(Conv2D(208, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "    \n",
    "    # preparing 3.b\n",
    "\n",
    "    model3_b = Sequential()\n",
    "    model3_b.add(ZeroPadding2D(padding=(1, 1), data_format=None, input_shape = img_size))\n",
    "    model3_b.add(MaxPooling2D(pool_size = (1,1), input_shape = img_size))\n",
    "    model3_b.add(ZeroPadding2D(padding=(0, 0), data_format=None))\n",
    "    model3_b.add(Conv2D(64, (1,1), input_shape = img_size, strides = 1, activation = \"relu\"))\n",
    "\n",
    "    model_3 = Concatenate([model3_a, model3_b])\n",
    "    \n",
    "    ## preparing final model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(model1)\n",
    "    model.add(model_2)\n",
    "    model.add(model_3)\n",
    "    \n",
    "    \n",
    "    #model.save(\"emoji_prediction.h5\")\n",
    "    \n",
    "    return model   # this will be feed t oh_list as input.\n",
    "\n",
    "###  Now, finally we have to add the classifier..\n",
    "\n",
    "history = preprocess()\n",
    "print(history.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbaeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the optimiser...\n",
    "\n",
    "    model.compile(optimizer = \"adam\", loss = \"sparse_categorial_crossentropy\", metrics = [\"sparse_categorical_accuracy\"])\n",
    "\n",
    "    ## training on test and validation set\n",
    "\n",
    "    model_overloading = model.fit(trainX, trainY, validation_data=(validX, validY), batch_size=128, epochs=6)\n",
    "\n",
    "    # test time !!\n",
    "\n",
    "    model_test_drive = model.evaluate(testX, testY, batch_size = 64, steps = 2)\n",
    "\n",
    "    # model_test_drive = [lest_loss, test_accuracy]\n",
    "\n",
    "    # plotting the test_drive datas :\n",
    "\n",
    "    \n",
    "    model.summary()\n",
    "    model.save(\"emoji_prediction.h5\")\n",
    "    \n",
    "    return history   # this will be feed t oh_list as input.\n",
    "\n",
    "###  Now, finally we have to add the classifier.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8c28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
