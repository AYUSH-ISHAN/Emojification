{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_svm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Get facial landmarks using pretrained dlib\n"
      ],
      "metadata": {
        "id": "gGXIereXI0z3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDRbLiqcdA85",
        "outputId": "d1356124-c256-4728-dcd4-c89fab6a664e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
        "# from keras.optimizers import RMSProp,Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, merge\n",
        "# from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import csv\n",
        "from PIL import Image    \n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tqdm import tqdm\n",
        "import numpy as np # linear algebra\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import collections\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWCZDuN0dMtO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# path = '/content/drive/My Drive/'\n",
        "path = '/content/drive/MyDrive/'\n",
        "\n",
        "\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C00pEboqdQfD"
      },
      "source": [
        "data = pd.read_csv(path+'challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc2B1dn9dTC3"
      },
      "source": [
        "def prepare_data(data):\n",
        "    \"\"\" Prepare data for modeling \n",
        "        input: data frame with labels und pixel data\n",
        "        output: image and label array \"\"\"\n",
        "    \n",
        "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\n",
        "    \n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image_array[i] = image\n",
        "        \n",
        "    return image_array, image_label\n",
        "# use pandarallel\n",
        "def plot_examples(label=0):\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n",
        "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
        "    axs = axs.ravel()\n",
        "    for i in range(5):\n",
        "        idx = data[data['emotion']==label].index[i]\n",
        "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
        "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_yticklabels([])\n",
        " \n",
        "def plot_all_emotions():\n",
        "    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n",
        "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
        "    axs = axs.ravel()\n",
        "    for i in range(7):\n",
        "        idx = data[data['emotion']==i].index[i]\n",
        "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
        "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_yticklabels([])\n",
        "        \n",
        "def plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n",
        "    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
        "    \n",
        "    bar_label = emotions.values()\n",
        "    \n",
        "    axs[0].imshow(test_image_array[image_number], 'gray')\n",
        "    axs[0].set_title(emotions[test_image_label[image_number]])\n",
        "    \n",
        "    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()\n",
        " \n",
        "def plot_compare_distributions(array1, array2, title1='', title2=''):\n",
        "    df_array1 = pd.DataFrame()\n",
        "    df_array2 = pd.DataFrame()\n",
        "    df_array1['emotion'] = array1.argmax(axis=1)\n",
        "    df_array2['emotion'] = array2.argmax(axis=1)\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
        "    x = emotions.values()\n",
        "    \n",
        "    y = df_array1['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[0].bar(x, y.sort_index(), color='orange')\n",
        "    axs[0].set_title(title1)\n",
        "    axs[0].grid()\n",
        "    \n",
        "    y = df_array2['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[1].bar(x, y.sort_index())\n",
        "    axs[1].set_title(title2)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lKrF5LUddaw"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2C1_Wb4deSI"
      },
      "source": [
        "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\n",
        "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\n",
        "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eJwuPyYdi3W"
      },
      "source": [
        "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\n",
        "# train_images = train_images.astype('float32')/255\n",
        "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\n",
        "# val_images = val_images.astype('float32')/255\n",
        "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\n",
        "# test_images = test_images.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo3hdZrBdjpn",
        "outputId": "2be30dad-c63f-4e90-a67e-acf57496c541"
      },
      "source": [
        "train_labels = to_categorical(train_image_label)\n",
        "val_labels = to_categorical(val_image_label)\n",
        "test_labels = to_categorical(test_image_label)\n",
        "\n",
        "print(np.shape(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYSn_wD7dpCJ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/drive/My Drive/shape_predictor_68_face_landmarks.dat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzzAThmLdrF4"
      },
      "source": [
        "train_final=[]\n",
        "detected=[]\n",
        "for q in range(28709):\n",
        "  \n",
        "  gray=np.array(train_images[q][:,:,:],dtype=np.uint8)\n",
        "  gray=cv2.resize(gray,(48,48))\n",
        "  faces=detector(gray,1)\n",
        "\n",
        "  if (np.shape(faces)[0]==0):\n",
        "    \n",
        "    continue\n",
        "  detected.append(q)\n",
        "  for face in faces:\n",
        "    x1=face.left()\n",
        "    y1=face.top()\n",
        "    x2=face.right()\n",
        "    y2=face.bottom()\n",
        " \n",
        "    landmarks=predictor(gray, face)\n",
        "    xlist=[]\n",
        "    ylist=[]\n",
        "    for n in range(0,68):\n",
        "      xlist.append(float(landmarks.part(n).x))\n",
        "      ylist.append(float(landmarks.part(n).y))\n",
        "\n",
        "    xmean=np.mean(xlist)\n",
        "    ymean=np.mean(ylist)\n",
        "    xcentral=[(x-xmean) for x in xlist] \n",
        "    ycentral=[(y-ymean) for y in ylist]\n",
        "    train_landmark=[]\n",
        "\n",
        "    for i,j in zip(xcentral,ycentral):\n",
        "\n",
        "      train_landmark.append([[i],[j]])\n",
        "\n",
        "    train_final.append(train_landmark)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjgbYhOOdvRR"
      },
      "source": [
        "train_final, final_train_labels = train_final, train_labels[detected]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUhlzqtTdxrY"
      },
      "source": [
        "val_final=[]\n",
        "detected=[]\n",
        "for q in range(3589):\n",
        " \n",
        "  gray=np.array(val_images[q][:,:,:],dtype=np.uint8)\n",
        "  gray=cv2.resize(gray,(48,48))\n",
        "  faces=detector(gray,1)\n",
        "\n",
        "  if (np.shape(faces)[0]==0):\n",
        "    \n",
        "    continue\n",
        "  detected.append(q)\n",
        "  for face in faces:\n",
        "    x1=face.left()\n",
        "    y1=face.top()\n",
        "    x2=face.right()\n",
        "    y2=face.bottom()\n",
        " \n",
        "    landmarks=predictor(gray, face)\n",
        "    xlist=[]\n",
        "    ylist=[]\n",
        "    for n in range(0,68):\n",
        "      xlist.append(float(landmarks.part(n).x))\n",
        "      ylist.append(float(landmarks.part(n).y))\n",
        "\n",
        "    xmean=np.mean(xlist)\n",
        "    ymean=np.mean(ylist)\n",
        "    xcentral=[(x-xmean) for x in xlist] \n",
        "    ycentral=[(y-ymean) for y in ylist]\n",
        "    train_landmark=[]\n",
        "\n",
        "    for i,j in zip(xcentral,ycentral):\n",
        "\n",
        "      train_landmark.append([[i],[j]])\n",
        "\n",
        "    val_final.append(train_landmark)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW_enw3bd1B8"
      },
      "source": [
        "final_val_images, final_val_labels = val_images[detected], val_labels[detected]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9a7R1g0d3BE"
      },
      "source": [
        "test_final=[]\n",
        "detected=[]\n",
        "for q in range(3589):\n",
        " \n",
        "  gray=np.array(test_images[q][:,:,:],dtype=np.uint8)\n",
        "  gray=cv2.resize(gray,(48,48))\n",
        "  faces=detector(gray,1)\n",
        "\n",
        "  if (np.shape(faces)[0]==0):\n",
        "    \n",
        "    continue\n",
        "  detected.append(q)\n",
        "  for face in faces:\n",
        "    x1=face.left()\n",
        "    y1=face.top()\n",
        "    x2=face.right()\n",
        "    y2=face.bottom()\n",
        " \n",
        "    landmarks=predictor(gray, face)\n",
        "    xlist=[]\n",
        "    ylist=[]\n",
        "    for n in range(0,68):\n",
        "      xlist.append(float(landmarks.part(n).x))\n",
        "      ylist.append(float(landmarks.part(n).y))\n",
        "\n",
        "    xmean=np.mean(xlist)\n",
        "    ymean=np.mean(ylist)\n",
        "    xcentral=[(x-xmean) for x in xlist] \n",
        "    ycentral=[(y-ymean) for y in ylist]\n",
        "    train_landmark=[]\n",
        "\n",
        "    for i,j in zip(xcentral,ycentral):\n",
        "\n",
        "      train_landmark.append([[i],[j]])\n",
        "\n",
        "    test_final.append(train_landmark)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9s5fmPbd6aI"
      },
      "source": [
        "final_test_images, final_test_lables = test_images[detected], test_labels[detected]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "refBdbSWd8r2"
      },
      "source": [
        "from keras.layers import Dense, PReLU, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59jjXbKWd_OF",
        "outputId": "ee252f99-a048-4ee2-9932-5f70f23e17d1"
      },
      "source": [
        "train_final=np.array(train_final)\n",
        "final_train_labels=np.array(final_train_labels)\n",
        "val_final=np.array(val_final)\n",
        "final_val_labels=np.array(final_val_labels)\n",
        "final_test_images = np.array(final_test_images)\n",
        "final_test_lables = np.array(final_test_lables)\n",
        "test_final=np.array(test_final)\n",
        "\n",
        "\n",
        "print(np.shape(train_final))\n",
        "print(np.shape(final_train_labels))\n",
        "print(np.shape(val_final))\n",
        "print(np.shape(final_val_labels))\n",
        "print(np.shape(test_final))\n",
        "print(np.shape(final_test_lables))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19984, 68, 2, 1)\n",
            "(19984, 7)\n",
            "(2471, 68, 2, 1)\n",
            "(2471, 7)\n",
            "(2487, 68, 2, 1)\n",
            "(2487, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using SVM to predict the emotion on the basis of the relative positions of the landmarks."
      ],
      "metadata": {
        "id": "RhionFjQJKJQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrWMLO1leBrd"
      },
      "source": [
        "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(train_final, final_train_labels)\n",
        "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(train_final, final_train_labels)\n",
        "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(train_final, final_train_labels)\n",
        "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(train_final, final_train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqqL6qx-eH0-"
      },
      "source": [
        "linear_pred = linear.predict(test_final)\n",
        "poly_pred = poly.predict(test_final)\n",
        "rbf_pred = rbf.predict(test_final)\n",
        "sig_pred = sig.predict(test_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjPtEmsseLgA"
      },
      "source": [
        "accuracy_lin = linear.score(test_final, final_test_labels)\n",
        "accuracy_poly = poly.score(test_final, final_test_labels)\n",
        "accuracy_rbf = rbf.score(test_final, final_test_labels)\n",
        "accuracy_sig = sig.score(test_final, final_test_labels)\n",
        "print(“Accuracy Linear Kernel:”, accuracy_lin)\n",
        "print(“Accuracy Polynomial Kernel:”, accuracy_poly)\n",
        "print(“Accuracy Radial Basis Kernel:”, accuracy_rbf)\n",
        "print(“Accuracy Sigmoid Kernel:”, accuracy_sig"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}